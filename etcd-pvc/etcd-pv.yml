apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  # "namespace" omitted since ClusterRoles are not namespaced
  name: lusterrole
rules:
- apiGroups: [""]
  resources: ["Deployment", "StatefulSet", "DaemonSet"]
  verbs: ["create"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-sa-name
  namespace: app-team1
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cicd-clusterrole-binging
subjects:
- kind: ServiceAccount
  name: my-sa-name
  namespace: app-team1
roleRef:
  kind: ClusterRole
  name: deployment-clusterrole
  apiGroup: rbac.authorization.k8s.io


****
mkdir /root/binaries
cd /root/binaries
wget https://github.com/etcd-io/etcd/releases/download/v3.4.0/etcd-v3.4.0-linux-amd64.tar.gz
tar -xzvf etcd-v3.4.0-linux-amd64.tar.gz
cd /root/binaries/etcd-v3.4.0-linux-amd64
cp etcd etcdctl /usr/bin/
***
#backup etcd
ETCDCTL_API=3 etcdctl snapshot save /opt/backup-etcd.db --endpoints=https://10.182.0.8:2379 --cacert="/ca.crt" --cert="/server.crt" --key="/server.key"
#etcd restore
ETCDCTL_API=3 etcdctl --write-out=table snapshot status /opt/backup-etcd.db
ETCDCTL_API=3 etcdctl --data-dir=/var/lib/backup-etcd snapshot restore /opt/backup-etcd.db
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-port-from-namespace
  namespace: eagunu
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          team: internal
    - ports:
      - port: 80
        protocol: TCP
      - port: 80
        protocol: UDP 
 ---
 apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: multi-port-egress
  namespace: cka
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          team: internaleage
    ports:
    - protocol: TCP
      port: 9000999

kubectl patch pvc "pv-volume" --namespace "default" --patch '{"spec": {"resources": {"request": {"storage": "100Mi"}}}}' --record



kubectl get node --selector='!node-role.kubernetes.io/master'
kubectl get node --selector='name=my-label'
kubectl get nodes -l=' name=my-label' -o=custom-columns=NAME:.metadata.name
*********
spec:
  initContainers:
  - name: create-log-file
    image: busybox
    command:
      - sh
      - -c
      - |
          #!/bin/sh
          mkdir -p /var/log/k8slog
          touch /var/log/k8slog/application.log
# Mount varlog volume to the Init container
    volumeMounts:
    - name: varlog
      mountPath: /var/log

  **containers:
      
  - name: count-log-1
    image: busybox
    args: [/bin/sh, -c, 'tail -f -n+1 -f  /var/log/k8slog/application.log']
# Mount varlog volume to count-log-1 container
    volumeMounts:
    - name: varlog
      mountPath: /var/log
*******

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv0003
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  hostPath:
    path: /tmp

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myclaim
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 8Gi
  storageClassName: slow

apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
      - mountPath: "/var/www/html"
        name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: myclaim
